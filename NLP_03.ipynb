{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPw4eKcmHJYtuZAM0u1fO7a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BandaAkshitha/Natural-Language-Processing/blob/main/NLP_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhQUM951hEf9",
        "outputId": "315276ae-ba06-44a8-ce86-17125272e572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Students', 'NNS'), ('are', 'VBP'), ('learning', 'VBG'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP')]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "sentence=\"Students are learning Natural Language Processing\"\n",
        "tokens=nltk.word_tokenize(sentence)\n",
        "pos_tags=nltk.pos_tag(tokens)\n",
        "print(pos_tags)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"Apple is looking at buying a startup in India.\")\n",
        "for token in doc:\n",
        "  print(token.text,token.pos_,token.tag_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOwntTeCng-M",
        "outputId": "ea56f6c2-8212-4fd6-d616-9b9f4edf48ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple PROPN NNP\n",
            "is AUX VBZ\n",
            "looking VERB VBG\n",
            "at ADP IN\n",
            "buying VERB VBG\n",
            "a DET DT\n",
            "startup NOUN NN\n",
            "in ADP IN\n",
            "India PROPN NNP\n",
            ". PUNCT .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"Students are learning Natural Language Processing\")\n",
        "for token in doc:\n",
        "  print(token.text,token.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7NZY8qenzzm",
        "outputId": "8aa0db45-15db-4129-c319-73b8c0e4e99a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Students NOUN\n",
            "are AUX\n",
            "learning VERB\n",
            "Natural PROPN\n",
            "Language PROPN\n",
            "Processing NOUN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "text=\"Loving the new AI features #AI #MachineLearning\"\n",
        "doc=nlp(text)\n",
        "nouns=[]\n",
        "verbs=[]\n",
        "for token in doc:\n",
        "  if token.pos_ in [\"NOUN\",\"PROPN\"]:\n",
        "    nouns.append(token.text)\n",
        "  elif token.pos_==\"VERB\":\n",
        "    verbs.append(token.text)\n",
        "noun_freq=Counter(nouns)\n",
        "verb_freq=Counter(verbs)\n",
        "print(\"Noun Frequency:\",noun_freq)\n",
        "print(\"Verb Frequency:\",verb_freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6CYUY3qotxn",
        "outputId": "33c9fc96-f4a6-45bc-a7df-6df2d36f1889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noun Frequency: Counter({'AI': 2, 'MachineLearning': 1})\n",
            "Verb Frequency: Counter({'Loving': 1, 'features': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from collections import Counter\n",
        "pos_tags_nltk=nltk.pos_tag(tokens)\n",
        "nouns_nltk=[]\n",
        "verbs_nltk=[]\n",
        "for word,tag in pos_tags_nltk:\n",
        "  if tag.startswith(\"NN\"):\n",
        "    nouns_nltk.append(word)\n",
        "  elif tag.startswith(\"VB\"):\n",
        "    verbs_nltk.append(word)\n",
        "noun_freq_nltk=Counter(nouns_nltk)\n",
        "verb_freq_nltk=Counter(verbs_nltk)\n",
        "print(\"NLTK Noun Frequency:\",noun_freq_nltk)\n",
        "print(\"NLTK Verb frequency:\",verb_freq_nltk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a56ifzNwqr3K",
        "outputId": "8c5f5690-a950-4e57-e57c-bb94a5b0ea58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Noun Frequency: Counter({'Students': 1, 'Natural': 1, 'Language': 1, 'Processing': 1})\n",
            "NLTK Verb frequency: Counter({'are': 1, 'learning': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "POS WITH SR UNIVERSITY"
      ],
      "metadata": {
        "id": "q0aIOFlcsJr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "sentence = SRUniversity=\"\"\"The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India.\n",
        "It is in 150 acres, with both separate hostel facilities for boys and girls.\n",
        "There is a huge central library along with Indias largest Technology Business Incubator (TBI) in tier 2 cities.\"\"\"\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "print(pos_tags)"
      ],
      "metadata": {
        "id": "jPhw4kgQsOiE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e46fea4-8bcf-4ebc-c1b2-35e8474c726d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT'), ('SR', 'NNP'), ('University', 'NNP'), ('campus', 'NN'), ('is', 'VBZ'), ('located', 'VBN'), ('in', 'IN'), ('Ananthasagar', 'NNP'), ('village', 'NN'), ('of', 'IN'), ('Hasanparthy', 'NNP'), ('Mandal', 'NNP'), ('in', 'IN'), ('Warangal', 'NNP'), (',', ','), ('Telangana', 'NNP'), (',', ','), ('India', 'NNP'), ('.', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('in', 'IN'), ('150', 'CD'), ('acres', 'NNS'), (',', ','), ('with', 'IN'), ('both', 'DT'), ('separate', 'JJ'), ('hostel', 'NN'), ('facilities', 'NNS'), ('for', 'IN'), ('boys', 'NNS'), ('and', 'CC'), ('girls', 'NNS'), ('.', '.'), ('There', 'EX'), ('is', 'VBZ'), ('a', 'DT'), ('huge', 'JJ'), ('central', 'JJ'), ('library', 'NN'), ('along', 'IN'), ('with', 'IN'), ('Indias', 'NNP'), ('largest', 'JJS'), ('Technology', 'NN'), ('Business', 'NNP'), ('Incubator', 'NNP'), ('(', '('), ('TBI', 'NNP'), (')', ')'), ('in', 'IN'), ('tier', '$'), ('2', 'CD'), ('cities', 'NNS'), ('.', '.')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# The variable 'sentence' from a previous cell already contains the multi-line text.\n",
        "# If 'sentence' was not defined, it would need to be defined using triple quotes like this:\n",
        "# sentence = \"\"\"The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India.\n",
        "# It is in 150 acres, with both separate hostel facilities for boys and girls.\n",
        "# There is a huge central library along with Indias largest Technology Business Incubator (TBI) in tier 2 cities.\"\"\"\n",
        "\n",
        "doc = nlp(sentence)\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaAWCiNgs3M1",
        "outputId": "d0973968-0805-48f1-8265-8282be3ef86e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The DET\n",
            "SR PROPN\n",
            "University PROPN\n",
            "campus NOUN\n",
            "is AUX\n",
            "located VERB\n",
            "in ADP\n",
            "Ananthasagar PROPN\n",
            "village NOUN\n",
            "of ADP\n",
            "Hasanparthy PROPN\n",
            "Mandal PROPN\n",
            "in ADP\n",
            "Warangal PROPN\n",
            ", PUNCT\n",
            "Telangana PROPN\n",
            ", PUNCT\n",
            "India PROPN\n",
            ". PUNCT\n",
            "\n",
            " SPACE\n",
            "It PRON\n",
            "is AUX\n",
            "in ADP\n",
            "150 NUM\n",
            "acres NOUN\n",
            ", PUNCT\n",
            "with ADP\n",
            "both DET\n",
            "separate ADJ\n",
            "hostel NOUN\n",
            "facilities NOUN\n",
            "for ADP\n",
            "boys NOUN\n",
            "and CCONJ\n",
            "girls NOUN\n",
            ". PUNCT\n",
            "\n",
            " SPACE\n",
            "There PRON\n",
            "is VERB\n",
            "a DET\n",
            "huge ADJ\n",
            "central ADJ\n",
            "library NOUN\n",
            "along ADP\n",
            "with ADP\n",
            "Indias PROPN\n",
            "largest ADJ\n",
            "Technology PROPN\n",
            "Business PROPN\n",
            "Incubator PROPN\n",
            "( PUNCT\n",
            "TBI PROPN\n",
            ") PUNCT\n",
            "in ADP\n",
            "tier NOUN\n",
            "2 NUM\n",
            "cities NOUN\n",
            ". PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# The variable 'sentence' from a previous cell already contains the multi-line text.\n",
        "# If 'sentence' was not defined, it would need to be defined using triple quotes like this:\n",
        "# sentence = \"\"\"The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India.\n",
        "# It is in 150 acres, with both separate hostel facilities for boys and girls.\n",
        "# There is a huge central library along with Indias largest Technology Business Incubator (TBI) in tier 2 cities.\"\"\"\n",
        "\n",
        "doc = nlp(sentence)\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_,token.tag_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TylrTdEatbK6",
        "outputId": "499548c2-4092-419b-a03b-5ec5563c1453"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The DET DT\n",
            "SR PROPN NNP\n",
            "University PROPN NNP\n",
            "campus NOUN NN\n",
            "is AUX VBZ\n",
            "located VERB VBN\n",
            "in ADP IN\n",
            "Ananthasagar PROPN NNP\n",
            "village NOUN NN\n",
            "of ADP IN\n",
            "Hasanparthy PROPN NNP\n",
            "Mandal PROPN NNP\n",
            "in ADP IN\n",
            "Warangal PROPN NNP\n",
            ", PUNCT ,\n",
            "Telangana PROPN NNP\n",
            ", PUNCT ,\n",
            "India PROPN NNP\n",
            ". PUNCT .\n",
            "\n",
            " SPACE _SP\n",
            "It PRON PRP\n",
            "is AUX VBZ\n",
            "in ADP IN\n",
            "150 NUM CD\n",
            "acres NOUN NNS\n",
            ", PUNCT ,\n",
            "with ADP IN\n",
            "both DET DT\n",
            "separate ADJ JJ\n",
            "hostel NOUN NN\n",
            "facilities NOUN NNS\n",
            "for ADP IN\n",
            "boys NOUN NNS\n",
            "and CCONJ CC\n",
            "girls NOUN NNS\n",
            ". PUNCT .\n",
            "\n",
            " SPACE _SP\n",
            "There PRON EX\n",
            "is VERB VBZ\n",
            "a DET DT\n",
            "huge ADJ JJ\n",
            "central ADJ JJ\n",
            "library NOUN NN\n",
            "along ADP IN\n",
            "with ADP IN\n",
            "Indias PROPN NNP\n",
            "largest ADJ JJS\n",
            "Technology PROPN NNP\n",
            "Business PROPN NNP\n",
            "Incubator PROPN NNP\n",
            "( PUNCT -LRB-\n",
            "TBI PROPN NNP\n",
            ") PUNCT -RRB-\n",
            "in ADP IN\n",
            "tier NOUN NN\n",
            "2 NUM CD\n",
            "cities NOUN NNS\n",
            ". PUNCT .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# We can use the 'sentence' variable which already holds the multi-line text correctly.\n",
        "text = sentence\n",
        "doc = nlp(text)\n",
        "\n",
        "nouns = []\n",
        "verbs = []\n",
        "\n",
        "for token in doc:\n",
        "    if token.pos_ in [\"NOUN\", \"PROPN\"]:\n",
        "        nouns.append(token.text)\n",
        "    elif token.pos_ == \"VERB\":\n",
        "        verbs.append(token.text)\n",
        "\n",
        "noun_freq = Counter(nouns)\n",
        "verb_freq = Counter(verbs)\n",
        "\n",
        "print(\"Noun Frequency:\", noun_freq)\n",
        "print(\"Verb Frequency:\", verb_freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT0kycmCtoWx",
        "outputId": "04d52d54-107b-4261-cb37-585232577068"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noun Frequency: Counter({'SR': 1, 'University': 1, 'campus': 1, 'Ananthasagar': 1, 'village': 1, 'Hasanparthy': 1, 'Mandal': 1, 'Warangal': 1, 'Telangana': 1, 'India': 1, 'acres': 1, 'hostel': 1, 'facilities': 1, 'boys': 1, 'girls': 1, 'library': 1, 'Indias': 1, 'Technology': 1, 'Business': 1, 'Incubator': 1, 'TBI': 1, 'tier': 1, 'cities': 1})\n",
            "Verb Frequency: Counter({'located': 1, 'is': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from collections import Counter\n",
        "\n",
        "pos_tags_nltk = nltk.pos_tag(tokens)\n",
        "\n",
        "nouns_nltk = []\n",
        "verbs_nltk = []\n",
        "\n",
        "for word, tag in pos_tags_nltk:\n",
        "    if tag.startswith('NN'):\n",
        "        nouns_nltk.append(word)\n",
        "    elif tag.startswith('VB'):\n",
        "        verbs_nltk.append(word)\n",
        "\n",
        "noun_freq_nltk = Counter(nouns_nltk)\n",
        "verb_freq_nltk = Counter(verbs_nltk)\n",
        "\n",
        "print(\"NLTK Noun Frequency:\", noun_freq_nltk)\n",
        "print(\"NLTK Verb Frequency:\", verb_freq_nltk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCDv5varuQDS",
        "outputId": "6a59fbf9-cb76-47eb-8ea9-e43fddda1515"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Noun Frequency: Counter({'SR': 1, 'University': 1, 'campus': 1, 'Ananthasagar': 1, 'village': 1, 'Hasanparthy': 1, 'Mandal': 1, 'Warangal': 1, 'Telangana': 1, 'India': 1, 'acres': 1, 'hostel': 1, 'facilities': 1, 'boys': 1, 'girls': 1, 'library': 1, 'Indias': 1, 'Technology': 1, 'Business': 1, 'Incubator': 1, 'TBI': 1, 'cities': 1})\n",
            "NLTK Verb Frequency: Counter({'is': 3, 'located': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ASSIGNMENT"
      ],
      "metadata": {
        "id": "1DcQBHmtufQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "import nltk\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfSw7v0iuhNk",
        "outputId": "866d3f44-e78c-4df5-be54-c599d6082b45"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.21.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2026.1.4)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ByZb2uivu5N",
        "outputId": "21b5fc8d-acf2-4f4a-fd4b-84af0076a171"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "essay_text = \"\"\"\n",
        "Academic writing plays a crucial role in communicating research findings.\n",
        "Researchers analyze data carefully and present arguments logically.\n",
        "The study demonstrates how language structure influences clarity and meaning.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "kNiF_N7ev8eK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk_tokens = word_tokenize(essay_text)\n",
        "print(nltk_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR5MroLIwFkV",
        "outputId": "5819d5dd-bffb-4190-8230-8b66aef18c1f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Academic', 'writing', 'plays', 'a', 'crucial', 'role', 'in', 'communicating', 'research', 'findings', '.', 'Researchers', 'analyze', 'data', 'carefully', 'and', 'present', 'arguments', 'logically', '.', 'The', 'study', 'demonstrates', 'how', 'language', 'structure', 'influences', 'clarity', 'and', 'meaning', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(essay_text)\n",
        "\n",
        "spacy_tokens = [token.text for token in doc]\n",
        "print(spacy_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf0gCHbbwLGx",
        "outputId": "8671d8f4-5752-4be5-d4d9-eba34401ddb5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', 'Academic', 'writing', 'plays', 'a', 'crucial', 'role', 'in', 'communicating', 'research', 'findings', '.', '\\n', 'Researchers', 'analyze', 'data', 'carefully', 'and', 'present', 'arguments', 'logically', '.', '\\n', 'The', 'study', 'demonstrates', 'how', 'language', 'structure', 'influences', 'clarity', 'and', 'meaning', '.', '\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_pos=nltk.pos_tag(nltk_tokens)\n",
        "nltk_pos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvbo-umhwUhO",
        "outputId": "85e15522-3923-4f7c-c550-a87e5e654a43"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Academic', 'NNP'),\n",
              " ('writing', 'NN'),\n",
              " ('plays', 'VBZ'),\n",
              " ('a', 'DT'),\n",
              " ('crucial', 'JJ'),\n",
              " ('role', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('communicating', 'VBG'),\n",
              " ('research', 'NN'),\n",
              " ('findings', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('Researchers', 'NNS'),\n",
              " ('analyze', 'VBP'),\n",
              " ('data', 'NNS'),\n",
              " ('carefully', 'RB'),\n",
              " ('and', 'CC'),\n",
              " ('present', 'JJ'),\n",
              " ('arguments', 'NNS'),\n",
              " ('logically', 'RB'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('study', 'NN'),\n",
              " ('demonstrates', 'VBZ'),\n",
              " ('how', 'WRB'),\n",
              " ('language', 'NN'),\n",
              " ('structure', 'NN'),\n",
              " ('influences', 'VBZ'),\n",
              " ('clarity', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('meaning', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_pos=[(token.text,token.pos_)for token in doc]\n",
        "spacy_pos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7h5Qj8Mwhtb",
        "outputId": "0cb53668-2ed2-4fdb-f6cf-5f0520b03259"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('\\n', 'SPACE'),\n",
              " ('Academic', 'ADJ'),\n",
              " ('writing', 'NOUN'),\n",
              " ('plays', 'VERB'),\n",
              " ('a', 'DET'),\n",
              " ('crucial', 'ADJ'),\n",
              " ('role', 'NOUN'),\n",
              " ('in', 'ADP'),\n",
              " ('communicating', 'VERB'),\n",
              " ('research', 'NOUN'),\n",
              " ('findings', 'NOUN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('\\n', 'SPACE'),\n",
              " ('Researchers', 'NOUN'),\n",
              " ('analyze', 'VERB'),\n",
              " ('data', 'NOUN'),\n",
              " ('carefully', 'ADV'),\n",
              " ('and', 'CCONJ'),\n",
              " ('present', 'ADJ'),\n",
              " ('arguments', 'NOUN'),\n",
              " ('logically', 'ADV'),\n",
              " ('.', 'PUNCT'),\n",
              " ('\\n', 'SPACE'),\n",
              " ('The', 'DET'),\n",
              " ('study', 'NOUN'),\n",
              " ('demonstrates', 'VERB'),\n",
              " ('how', 'SCONJ'),\n",
              " ('language', 'NOUN'),\n",
              " ('structure', 'NOUN'),\n",
              " ('influences', 'VERB'),\n",
              " ('clarity', 'NOUN'),\n",
              " ('and', 'CCONJ'),\n",
              " ('meaning', 'NOUN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('\\n', 'SPACE')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}