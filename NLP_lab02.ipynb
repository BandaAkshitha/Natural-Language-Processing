{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaHg0hDksmK0qKMwJ8XOe1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BandaAkshitha/Natural-Language-Processing/blob/main/NLP_lab02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment-2.4"
      ],
      "metadata": {
        "id": "CxEC4foRGZeG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "980NyhwTuurl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "242fa2c2-34b5-41da-8b5f-d360f9d5687e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T00-vQv8DTuW",
        "outputId": "20faecb5-0ffe-4e10-c8fe-254410e37801"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "medical_text = \"\"\"\n",
        "The patient was diagnosed with diabetes mellitus and hypertension.\n",
        "She was prescribed insulin therapy and antihypertensive medication.\n",
        "Regular monitoring of blood glucose levels is essential for managing diabetes.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "qIU463CjDiFd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk_sentences = sent_tokenize(medical_text)\n",
        "print(\"NLTK Sentence Tokenization:\")\n",
        "for sent in nltk_sentences:\n",
        "    print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLzrb70QDrZF",
        "outputId": "6dd53081-8030-46db-ea8e-be8161011d89"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Sentence Tokenization:\n",
            "\n",
            "The patient was diagnosed with diabetes mellitus and hypertension.\n",
            "She was prescribed insulin therapy and antihypertensive medication.\n",
            "Regular monitoring of blood glucose levels is essential for managing diabetes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(medical_text)\n",
        "spacy_sentences = [sent.text for sent in doc.sents]\n",
        "\n",
        "print(\"\\nspaCy Sentence Tokenization:\")\n",
        "for sent in spacy_sentences:\n",
        "    print(sent)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ag-84AVXD2t-",
        "outputId": "c116a035-9656-496b-b19b-3d9915c48bea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "spaCy Sentence Tokenization:\n",
            "\n",
            "The patient was diagnosed with diabetes mellitus and hypertension.\n",
            "\n",
            "She was prescribed insulin therapy and antihypertensive medication.\n",
            "\n",
            "Regular monitoring of blood glucose levels is essential for managing diabetes.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_words = word_tokenize(medical_text)\n",
        "print(\"NLTK Word Tokens:\")\n",
        "print(nltk_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aYt7CX8D7jt",
        "outputId": "353b98c6-128f-4424-abb5-027e1cc53cfa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Word Tokens:\n",
            "['The', 'patient', 'was', 'diagnosed', 'with', 'diabetes', 'mellitus', 'and', 'hypertension', '.', 'She', 'was', 'prescribed', 'insulin', 'therapy', 'and', 'antihypertensive', 'medication', '.', 'Regular', 'monitoring', 'of', 'blood', 'glucose', 'levels', 'is', 'essential', 'for', 'managing', 'diabetes', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_words = [token.text for token in doc]\n",
        "print(\"\\nspaCy Word Tokens:\")\n",
        "print(spacy_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F7Fr6JeD-x1",
        "outputId": "d6247cfa-0ef1-4516-ea72-e3799915085c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "spaCy Word Tokens:\n",
            "['\\n', 'The', 'patient', 'was', 'diagnosed', 'with', 'diabetes', 'mellitus', 'and', 'hypertension', '.', '\\n', 'She', 'was', 'prescribed', 'insulin', 'therapy', 'and', 'antihypertensive', 'medication', '.', '\\n', 'Regular', 'monitoring', 'of', 'blood', 'glucose', 'levels', 'is', 'essential', 'for', 'managing', 'diabetes', '.', '\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "stemmed_words = [stemmer.stem(word) for word in nltk_words if word.isalpha()]\n",
        "\n",
        "print(\"Stemmed Words:\")\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpP8XuyaED9E",
        "outputId": "60759b5a-8bff-49e6-8483-1fb018aa1215"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Words:\n",
            "['the', 'patient', 'wa', 'diagnos', 'with', 'diabet', 'mellitu', 'and', 'hypertens', 'she', 'wa', 'prescrib', 'insulin', 'therapi', 'and', 'antihypertens', 'medic', 'regular', 'monitor', 'of', 'blood', 'glucos', 'level', 'is', 'essenti', 'for', 'manag', 'diabet']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "lemmatized_words_nltk = [lemmatizer.lemmatize(word.lower())\n",
        "                          for word in nltk_words if word.isalpha()]\n",
        "\n",
        "print(\"NLTK Lemmatized Words:\")\n",
        "print(lemmatized_words_nltk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5rpbFziEGOk",
        "outputId": "e11fce3f-dd15-4121-9734-f3cec137cf00"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Lemmatized Words:\n",
            "['the', 'patient', 'wa', 'diagnosed', 'with', 'diabetes', 'mellitus', 'and', 'hypertension', 'she', 'wa', 'prescribed', 'insulin', 'therapy', 'and', 'antihypertensive', 'medication', 'regular', 'monitoring', 'of', 'blood', 'glucose', 'level', 'is', 'essential', 'for', 'managing', 'diabetes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_words_spacy = [token.lemma_ for token in doc if token.is_alpha]\n",
        "\n",
        "print(\"\\nspaCy Lemmatized Words:\")\n",
        "print(lemmatized_words_spacy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htddQ_zIEMFa",
        "outputId": "72174020-967b-4927-89fa-5682dc64cfb9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "spaCy Lemmatized Words:\n",
            "['the', 'patient', 'be', 'diagnose', 'with', 'diabete', 'mellitus', 'and', 'hypertension', 'she', 'be', 'prescribe', 'insulin', 'therapy', 'and', 'antihypertensive', 'medication', 'regular', 'monitoring', 'of', 'blood', 'glucose', 'level', 'be', 'essential', 'for', 'manage', 'diabetes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basics_Natural_Language_Processing_With_Python's_NLTK_Package"
      ],
      "metadata": {
        "id": "CXk7MaaBEjkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SRUniversity=\"\"\"The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India.\n",
        "It is in 150 acres, with both separate hostel facilities for boys and girls.\n",
        "There is a huge central library along with Indias largest Technology Business Incubator (TBI) in tier 2 cities.\"\"\"\n",
        ""
      ],
      "metadata": {
        "id": "67sxMe2zEvDi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SRUniversity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "10EulEF5FDYb",
        "outputId": "29f80c7b-110e-4648-8481-8360fac686a1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India. \\nIt is in 150 acres, with both separate hostel facilities for boys and girls. \\nThere is a huge central library along with Indias largest Technology Business Incubator (TBI) in tier 2 cities.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(SRUniversity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjyV_Jo3FHC1",
        "outputId": "7553426a-4d88-40e7-daa6-1603444af9c3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'SR',\n",
              " 'University',\n",
              " 'campus',\n",
              " 'is',\n",
              " 'located',\n",
              " 'in',\n",
              " 'Ananthasagar',\n",
              " 'village',\n",
              " 'of',\n",
              " 'Hasanparthy',\n",
              " 'Mandal',\n",
              " 'in',\n",
              " 'Warangal',\n",
              " ',',\n",
              " 'Telangana',\n",
              " ',',\n",
              " 'India',\n",
              " '.',\n",
              " 'It',\n",
              " 'is',\n",
              " 'in',\n",
              " '150',\n",
              " 'acres',\n",
              " ',',\n",
              " 'with',\n",
              " 'both',\n",
              " 'separate',\n",
              " 'hostel',\n",
              " 'facilities',\n",
              " 'for',\n",
              " 'boys',\n",
              " 'and',\n",
              " 'girls',\n",
              " '.',\n",
              " 'There',\n",
              " 'is',\n",
              " 'a',\n",
              " 'huge',\n",
              " 'central',\n",
              " 'library',\n",
              " 'along',\n",
              " 'with',\n",
              " 'Indias',\n",
              " 'largest',\n",
              " 'Technology',\n",
              " 'Business',\n",
              " 'Incubator',\n",
              " '(',\n",
              " 'TBI',\n",
              " ')',\n",
              " 'in',\n",
              " 'tier',\n",
              " '2',\n",
              " 'cities',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(SRUniversity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9B4ZlhCFN2u",
        "outputId": "609c9e8e-433e-4d7a-a350-263d3e490d36"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India.',\n",
              " 'It is in 150 acres, with both separate hostel facilities for boys and girls.',\n",
              " 'There is a huge central library along with Indias largest Technology Business Incubator (TBI) in tier 2 cities.']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HESJDAriFdFX",
        "outputId": "9812fd9d-26b3-45ff-8450-da14dac928c5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_quote = word_tokenize(SRUniversity)\n",
        "words_in_quote"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1HOb5wsFfdK",
        "outputId": "f1721cd2-ef5e-49f7-9432-b0ae926fa540"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'SR',\n",
              " 'University',\n",
              " 'campus',\n",
              " 'is',\n",
              " 'located',\n",
              " 'in',\n",
              " 'Ananthasagar',\n",
              " 'village',\n",
              " 'of',\n",
              " 'Hasanparthy',\n",
              " 'Mandal',\n",
              " 'in',\n",
              " 'Warangal',\n",
              " ',',\n",
              " 'Telangana',\n",
              " ',',\n",
              " 'India',\n",
              " '.',\n",
              " 'It',\n",
              " 'is',\n",
              " 'in',\n",
              " '150',\n",
              " 'acres',\n",
              " ',',\n",
              " 'with',\n",
              " 'both',\n",
              " 'separate',\n",
              " 'hostel',\n",
              " 'facilities',\n",
              " 'for',\n",
              " 'boys',\n",
              " 'and',\n",
              " 'girls',\n",
              " '.',\n",
              " 'There',\n",
              " 'is',\n",
              " 'a',\n",
              " 'huge',\n",
              " 'central',\n",
              " 'library',\n",
              " 'along',\n",
              " 'with',\n",
              " 'Indias',\n",
              " 'largest',\n",
              " 'Technology',\n",
              " 'Business',\n",
              " 'Incubator',\n",
              " '(',\n",
              " 'TBI',\n",
              " ')',\n",
              " 'in',\n",
              " 'tier',\n",
              " '2',\n",
              " 'cities',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_list = []\n",
        "for word in words_in_quote:\n",
        "  if word.casefold() not in stop_words:\n",
        "    filtered_list.append(word)\n",
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkQzs0ZOFjhH",
        "outputId": "a32b0fc4-2dda-46b2-cfa0-70b7dff1dc40"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SR',\n",
              " 'University',\n",
              " 'campus',\n",
              " 'located',\n",
              " 'Ananthasagar',\n",
              " 'village',\n",
              " 'Hasanparthy',\n",
              " 'Mandal',\n",
              " 'Warangal',\n",
              " ',',\n",
              " 'Telangana',\n",
              " ',',\n",
              " 'India',\n",
              " '.',\n",
              " '150',\n",
              " 'acres',\n",
              " ',',\n",
              " 'separate',\n",
              " 'hostel',\n",
              " 'facilities',\n",
              " 'boys',\n",
              " 'girls',\n",
              " '.',\n",
              " 'huge',\n",
              " 'central',\n",
              " 'library',\n",
              " 'along',\n",
              " 'Indias',\n",
              " 'largest',\n",
              " 'Technology',\n",
              " 'Business',\n",
              " 'Incubator',\n",
              " '(',\n",
              " 'TBI',\n",
              " ')',\n",
              " 'tier',\n",
              " '2',\n",
              " 'cities',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer = PorterStemmer()\n",
        "words = word_tokenize(SRUniversity)\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7GXyQOOFnm7",
        "outputId": "a6210040-2f31-4af8-cb97-8ed07ee1a2fe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'sr',\n",
              " 'univers',\n",
              " 'campu',\n",
              " 'is',\n",
              " 'locat',\n",
              " 'in',\n",
              " 'ananthasagar',\n",
              " 'villag',\n",
              " 'of',\n",
              " 'hasanparthi',\n",
              " 'mandal',\n",
              " 'in',\n",
              " 'warang',\n",
              " ',',\n",
              " 'telangana',\n",
              " ',',\n",
              " 'india',\n",
              " '.',\n",
              " 'it',\n",
              " 'is',\n",
              " 'in',\n",
              " '150',\n",
              " 'acr',\n",
              " ',',\n",
              " 'with',\n",
              " 'both',\n",
              " 'separ',\n",
              " 'hostel',\n",
              " 'facil',\n",
              " 'for',\n",
              " 'boy',\n",
              " 'and',\n",
              " 'girl',\n",
              " '.',\n",
              " 'there',\n",
              " 'is',\n",
              " 'a',\n",
              " 'huge',\n",
              " 'central',\n",
              " 'librari',\n",
              " 'along',\n",
              " 'with',\n",
              " 'india',\n",
              " 'largest',\n",
              " 'technolog',\n",
              " 'busi',\n",
              " 'incub',\n",
              " '(',\n",
              " 'tbi',\n",
              " ')',\n",
              " 'in',\n",
              " 'tier',\n",
              " '2',\n",
              " 'citi',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "snowball = SnowballStemmer(language='english')\n",
        "words = word_tokenize(SRUniversity)\n",
        "for word in words:\n",
        "    print(word,\"--->\",snowball.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiG_y9WAFsVZ",
        "outputId": "46a5413d-d0db-4a2f-b4a6-bf48f04f16ee"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> the\n",
            "SR ---> sr\n",
            "University ---> univers\n",
            "campus ---> campus\n",
            "is ---> is\n",
            "located ---> locat\n",
            "in ---> in\n",
            "Ananthasagar ---> ananthasagar\n",
            "village ---> villag\n",
            "of ---> of\n",
            "Hasanparthy ---> hasanparthi\n",
            "Mandal ---> mandal\n",
            "in ---> in\n",
            "Warangal ---> warang\n",
            ", ---> ,\n",
            "Telangana ---> telangana\n",
            ", ---> ,\n",
            "India ---> india\n",
            ". ---> .\n",
            "It ---> it\n",
            "is ---> is\n",
            "in ---> in\n",
            "150 ---> 150\n",
            "acres ---> acr\n",
            ", ---> ,\n",
            "with ---> with\n",
            "both ---> both\n",
            "separate ---> separ\n",
            "hostel ---> hostel\n",
            "facilities ---> facil\n",
            "for ---> for\n",
            "boys ---> boy\n",
            "and ---> and\n",
            "girls ---> girl\n",
            ". ---> .\n",
            "There ---> there\n",
            "is ---> is\n",
            "a ---> a\n",
            "huge ---> huge\n",
            "central ---> central\n",
            "library ---> librari\n",
            "along ---> along\n",
            "with ---> with\n",
            "Indias ---> india\n",
            "largest ---> largest\n",
            "Technology ---> technolog\n",
            "Business ---> busi\n",
            "Incubator ---> incub\n",
            "( ---> (\n",
            "TBI ---> tbi\n",
            ") ---> )\n",
            "in ---> in\n",
            "tier ---> tier\n",
            "2 ---> 2\n",
            "cities ---> citi\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import LancasterStemmer\n",
        "Lanc = LancasterStemmer()\n",
        "words = word_tokenize(SRUniversity)\n",
        "for word in words:\n",
        "    print(word,\"--->\",Lanc.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42iSMDGAFx48",
        "outputId": "b1442f83-0490-4764-e2c7-4d8c0154ac78"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> the\n",
            "SR ---> sr\n",
            "University ---> univers\n",
            "campus ---> camp\n",
            "is ---> is\n",
            "located ---> loc\n",
            "in ---> in\n",
            "Ananthasagar ---> ananthasag\n",
            "village ---> vil\n",
            "of ---> of\n",
            "Hasanparthy ---> hasanparthy\n",
            "Mandal ---> mand\n",
            "in ---> in\n",
            "Warangal ---> warang\n",
            ", ---> ,\n",
            "Telangana ---> telangan\n",
            ", ---> ,\n",
            "India ---> ind\n",
            ". ---> .\n",
            "It ---> it\n",
            "is ---> is\n",
            "in ---> in\n",
            "150 ---> 150\n",
            "acres ---> acr\n",
            ", ---> ,\n",
            "with ---> with\n",
            "both ---> both\n",
            "separate ---> sep\n",
            "hostel ---> hostel\n",
            "facilities ---> facil\n",
            "for ---> for\n",
            "boys ---> boy\n",
            "and ---> and\n",
            "girls ---> girl\n",
            ". ---> .\n",
            "There ---> ther\n",
            "is ---> is\n",
            "a ---> a\n",
            "huge ---> hug\n",
            "central ---> cent\n",
            "library ---> libr\n",
            "along ---> along\n",
            "with ---> with\n",
            "Indias ---> india\n",
            "largest ---> largest\n",
            "Technology ---> technolog\n",
            "Business ---> busy\n",
            "Incubator ---> incub\n",
            "( ---> (\n",
            "TBI ---> tbi\n",
            ") ---> )\n",
            "in ---> in\n",
            "tier ---> tier\n",
            "2 ---> 2\n",
            "cities ---> city\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "regexp = RegexpStemmer('ing|s|e|able', min=4)\n",
        "words = word_tokenize(SRUniversity)\n",
        "for word in words:\n",
        "    print(word,\"--->\",Lanc.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0mFd5mfF28u",
        "outputId": "fc7772b3-1437-4a2c-ccfe-255e784c59ad"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> the\n",
            "SR ---> sr\n",
            "University ---> univers\n",
            "campus ---> camp\n",
            "is ---> is\n",
            "located ---> loc\n",
            "in ---> in\n",
            "Ananthasagar ---> ananthasag\n",
            "village ---> vil\n",
            "of ---> of\n",
            "Hasanparthy ---> hasanparthy\n",
            "Mandal ---> mand\n",
            "in ---> in\n",
            "Warangal ---> warang\n",
            ", ---> ,\n",
            "Telangana ---> telangan\n",
            ", ---> ,\n",
            "India ---> ind\n",
            ". ---> .\n",
            "It ---> it\n",
            "is ---> is\n",
            "in ---> in\n",
            "150 ---> 150\n",
            "acres ---> acr\n",
            ", ---> ,\n",
            "with ---> with\n",
            "both ---> both\n",
            "separate ---> sep\n",
            "hostel ---> hostel\n",
            "facilities ---> facil\n",
            "for ---> for\n",
            "boys ---> boy\n",
            "and ---> and\n",
            "girls ---> girl\n",
            ". ---> .\n",
            "There ---> ther\n",
            "is ---> is\n",
            "a ---> a\n",
            "huge ---> hug\n",
            "central ---> cent\n",
            "library ---> libr\n",
            "along ---> along\n",
            "with ---> with\n",
            "Indias ---> india\n",
            "largest ---> largest\n",
            "Technology ---> technolog\n",
            "Business ---> busy\n",
            "Incubator ---> incub\n",
            "( ---> (\n",
            "TBI ---> tbi\n",
            ") ---> )\n",
            "in ---> in\n",
            "tier ---> tier\n",
            "2 ---> 2\n",
            "cities ---> city\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = word_tokenize(SRUniversity)\n",
        "for word in words:\n",
        "    print(word,\"--->\",lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7u7zI_zzGMfm",
        "outputId": "47d1e5f0-7bf7-4852-efbb-d1e596bd61ae"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> The\n",
            "SR ---> SR\n",
            "University ---> University\n",
            "campus ---> campus\n",
            "is ---> is\n",
            "located ---> located\n",
            "in ---> in\n",
            "Ananthasagar ---> Ananthasagar\n",
            "village ---> village\n",
            "of ---> of\n",
            "Hasanparthy ---> Hasanparthy\n",
            "Mandal ---> Mandal\n",
            "in ---> in\n",
            "Warangal ---> Warangal\n",
            ", ---> ,\n",
            "Telangana ---> Telangana\n",
            ", ---> ,\n",
            "India ---> India\n",
            ". ---> .\n",
            "It ---> It\n",
            "is ---> is\n",
            "in ---> in\n",
            "150 ---> 150\n",
            "acres ---> acre\n",
            ", ---> ,\n",
            "with ---> with\n",
            "both ---> both\n",
            "separate ---> separate\n",
            "hostel ---> hostel\n",
            "facilities ---> facility\n",
            "for ---> for\n",
            "boys ---> boy\n",
            "and ---> and\n",
            "girls ---> girl\n",
            ". ---> .\n",
            "There ---> There\n",
            "is ---> is\n",
            "a ---> a\n",
            "huge ---> huge\n",
            "central ---> central\n",
            "library ---> library\n",
            "along ---> along\n",
            "with ---> with\n",
            "Indias ---> Indias\n",
            "largest ---> largest\n",
            "Technology ---> Technology\n",
            "Business ---> Business\n",
            "Incubator ---> Incubator\n",
            "( ---> (\n",
            "TBI ---> TBI\n",
            ") ---> )\n",
            "in ---> in\n",
            "tier ---> tier\n",
            "2 ---> 2\n",
            "cities ---> city\n",
            ". ---> .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"worst\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hPVDO5OcGR3E",
        "outputId": "d5bf96c8-dde5-4b55-c5fd-bed112db030a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'worst'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"worst\", pos=\"a\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6ddj8NCiGTjc",
        "outputId": "ffea5bb8-5257-4fa4-de31-566d50351328"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write preprocessing output for:\n",
        "“NLP models are transforming the world rapidly!”\n",
        "Submit:\n",
        "1⃣ Word tokens\n",
        "2⃣ Stemmed words\n",
        "3⃣ Lemmatized words\n"
      ],
      "metadata": {
        "id": "-A3htorgIiqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Word Tokens"
      ],
      "metadata": {
        "id": "CGrRp9TfItso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "['NLP', 'models', 'are', 'transforming', 'the', 'world', 'rapidly', '!']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_U9cSLSIqRz",
        "outputId": "e0642242-cff0-46e2-8946-179e26273b1c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLP', 'models', 'are', 'transforming', 'the', 'world', 'rapidly', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Stemmed words"
      ],
      "metadata": {
        "id": "sNbf9IF3I3KR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "['nlp', 'model', 'are', 'transform', 'the', 'world', 'rapidli']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0eHjhqYI7U4",
        "outputId": "f5699e0c-ca43-4ef1-947f-ef6f64aeb3b1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nlp', 'model', 'are', 'transform', 'the', 'world', 'rapidli']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Lemmatized words"
      ],
      "metadata": {
        "id": "eqsmNFYAI-vG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "['NLP', 'model', 'be', 'transform', 'the', 'world', 'rapidly']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZDIIGRMJC2-",
        "outputId": "11e97990-2545-473a-ed68-d83e2ac8993e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLP', 'model', 'be', 'transform', 'the', 'world', 'rapidly']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}