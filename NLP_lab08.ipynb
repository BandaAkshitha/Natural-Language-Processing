{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6Ia1SNuZLLwFBpSI6JCbO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BandaAkshitha/Natural-Language-Processing/blob/main/NLP_lab08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Corpus"
      ],
      "metadata": {
        "id": "daGGhDbpG7or"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oGpI4YmQxvPX"
      },
      "outputs": [],
      "source": [
        "D1=\"AI is used in daily life\"\n",
        "D2=\"NLP uses language models to predict text\"\n",
        "D3=\"Technology improves education\"\n",
        "D4=\"Smart systems help protect the environment\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uni Gram Counts"
      ],
      "metadata": {
        "id": "odXyoBlnG2Xz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "# Combine the text from D1, D2, D3, D4\n",
        "combined_text = f\"{D1} {D2} {D3} {D4}\"\n",
        "\n",
        "# Tokenize the combined text into words and convert to lowercase\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "# Calculate unigram counts\n",
        "unigram_counts = collections.Counter(words)\n",
        "\n",
        "# Print the unigram counts\n",
        "print(\"Unigram Counts:\")\n",
        "for word, count in unigram_counts.most_common():\n",
        "    print(f\"{word}: {count}\")\n",
        "#Vocabulary size is length of unigrams\n",
        "V=len(unigram_counts)\n",
        "print(\"Vocabulary Size=\",V)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypbJtOSS-ysj",
        "outputId": "754e0776-55bb-4840-bed0-503d91cce5bb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Counts:\n",
            "ai: 1\n",
            "is: 1\n",
            "used: 1\n",
            "in: 1\n",
            "daily: 1\n",
            "life: 1\n",
            "nlp: 1\n",
            "uses: 1\n",
            "language: 1\n",
            "models: 1\n",
            "to: 1\n",
            "predict: 1\n",
            "text: 1\n",
            "technology: 1\n",
            "improves: 1\n",
            "education: 1\n",
            "smart: 1\n",
            "systems: 1\n",
            "help: 1\n",
            "protect: 1\n",
            "the: 1\n",
            "environment: 1\n",
            "Vocabulary Size= 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bi-Gram Counts"
      ],
      "metadata": {
        "id": "wG2G4pUjGxvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "\n",
        "combined_text = f\"{D1} {D2} {D3} {D4}\"\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "# Generate bigrams\n",
        "bigrams = []\n",
        "for i in range(len(words) - 1):\n",
        "    bigrams.append((words[i], words[i+1]))\n",
        "\n",
        "# Calculate bigram counts\n",
        "bigram_counts = collections.Counter(bigrams)\n",
        "\n",
        "# Print the bigram counts\n",
        "print(\"\\nBigram Counts:\")\n",
        "for bigram, count in bigram_counts.most_common():\n",
        "    print(f\"{bigram[0]} {bigram[1]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t99VXmDw-4KS",
        "outputId": "8a70cf82-e0b7-4084-d201-a3c2d5b3ca41"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bigram Counts:\n",
            "ai is: 1\n",
            "is used: 1\n",
            "used in: 1\n",
            "in daily: 1\n",
            "daily life: 1\n",
            "life nlp: 1\n",
            "nlp uses: 1\n",
            "uses language: 1\n",
            "language models: 1\n",
            "models to: 1\n",
            "to predict: 1\n",
            "predict text: 1\n",
            "text technology: 1\n",
            "technology improves: 1\n",
            "improves education: 1\n",
            "education smart: 1\n",
            "smart systems: 1\n",
            "systems help: 1\n",
            "help protect: 1\n",
            "protect the: 1\n",
            "the environment: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tri-Gram Counts"
      ],
      "metadata": {
        "id": "JSwBtQPeGsus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "\n",
        "combined_text = f\"{D1} {D2} {D3} {D4}\"\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "# Generate bigrams\n",
        "bigrams = []\n",
        "for i in range(len(words) - 1):\n",
        "    bigrams.append((words[i], words[i+1]))\n",
        "\n",
        "# Calculate bigram counts\n",
        "bigram_counts = collections.Counter(bigrams)\n",
        "\n",
        "# Print the bigram counts\n",
        "print(\"\\nBigram Counts:\")\n",
        "for bigram, count in bigram_counts.most_common():\n",
        "    print(f\"{bigram[0]} {bigram[1]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kO52cbaL_Eox",
        "outputId": "1d8669c9-5aab-4175-e2ea-c6666a1927fd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bigram Counts:\n",
            "ai is: 1\n",
            "is used: 1\n",
            "used in: 1\n",
            "in daily: 1\n",
            "daily life: 1\n",
            "life nlp: 1\n",
            "nlp uses: 1\n",
            "uses language: 1\n",
            "language models: 1\n",
            "models to: 1\n",
            "to predict: 1\n",
            "predict text: 1\n",
            "text technology: 1\n",
            "technology improves: 1\n",
            "improves education: 1\n",
            "education smart: 1\n",
            "smart systems: 1\n",
            "systems help: 1\n",
            "help protect: 1\n",
            "protect the: 1\n",
            "the environment: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Bi-Gram Counts"
      ],
      "metadata": {
        "id": "oAACol-jGnV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram(word_sequence, bigram_counts, unigram_counts):\n",
        "\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find possible next words\n",
        "    potential_next_words = {}\n",
        "\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = 0\n",
        "\n",
        "    print(f\"\\nPossible next words for '{last_word}':\")\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = bigram_count / last_word_unigram_count\n",
        "        print(f\"Probability of '{next_word}' = {probability}\")\n",
        "\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "sequence1 = \"artificial\"\n",
        "print(\"\\nPredicted word:\", predict_next_word_bigram(sequence1, bigram_counts, unigram_counts))\n",
        "\n",
        "sequence2 = \"language\"\n",
        "print(\"\\nPredicted word:\", predict_next_word_bigram(sequence2, bigram_counts, unigram_counts))\n",
        "\n",
        "sequence3 = \"online\"\n",
        "print(\"\\nPredicted word:\", predict_next_word_bigram(sequence3, bigram_counts, unigram_counts))\n",
        "\n",
        "sequence4 = \"smart\"\n",
        "print(\"\\nPredicted word:\", predict_next_word_bigram(sequence4, bigram_counts, unigram_counts))\n",
        "\n",
        "sequence5 = \"unknownword\"\n",
        "print(\"\\nPredicted word:\", predict_next_word_bigram(sequence5, bigram_counts, unigram_counts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyCBVpQo_3FM",
        "outputId": "bff8dc2b-fbba-4dcd-a61d-e1c868fff9a6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted word: No bigram found starting with 'artificial'.\n",
            "\n",
            "Possible next words for 'language':\n",
            "Probability of 'models' = 1.0\n",
            "\n",
            "Predicted word: models\n",
            "\n",
            "Predicted word: No bigram found starting with 'online'.\n",
            "\n",
            "Possible next words for 'smart':\n",
            "Probability of 'systems' = 1.0\n",
            "\n",
            "Predicted word: systems\n",
            "\n",
            "Predicted word: No bigram found starting with 'unknownword'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Bi-Gram Model"
      ],
      "metadata": {
        "id": "ZCkB0PU5GeC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBwPu2crAMXJ",
        "outputId": "a0e60a2c-526c-4fe0-ea7f-4f19d9252ce2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textAI is\n",
            "\n",
            "Possible next words for 'is':\n",
            "Probability of 'used' = 1.0\n",
            "Given sequence: 'AI is', predicted next word: 'used'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Tri-Gram Counts"
      ],
      "metadata": {
        "id": "U_oTC7OdGZjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram(word_sequence, Trigrams_counts, bigram_counts):\n",
        "\n",
        "    # Tokenize input\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Need at least 2 words\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words.\"\n",
        "\n",
        "    # Last two words\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find possible next words\n",
        "    potential_next_words = {}\n",
        "\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}.'\"\n",
        "\n",
        "    # Bigram count for denominator\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{ ' '.join(last_two_words_tuple) }' not found as bigram.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = 0\n",
        "\n",
        "    print(f\"\\nPossible next words for '{' '.join(last_two_words_tuple)}':\")\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = trigram_count / last_two_words_bigram_count\n",
        "        print(f\"Probability of '{next_word}' = {probability}\")\n",
        "\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "\n",
        "# Generate trigrams\n",
        "trigrams = []\n",
        "for i in range(len(words) - 2):\n",
        "    trigrams.append((words[i], words[i+1], words[i+2]))\n",
        "\n",
        "# Calculate trigram counts\n",
        "Trigrams_counts = collections.Counter(trigrams)\n",
        "\n",
        "\n",
        "sequence1 = \"ai is\"\n",
        "next_word1 = predict_next_word_trigram(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"\\nGiven sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"nlp uses\"\n",
        "next_word2 = predict_next_word_trigram(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"\\nGiven sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"technology improves\"\n",
        "next_word3 = predict_next_word_trigram(sequence3, Trigrams_counts, bigram_counts)\n",
        "print(f\"\\nGiven sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"smart systems\"\n",
        "next_word4 = predict_next_word_trigram(sequence4, Trigrams_counts, bigram_counts)\n",
        "print(f\"\\nGiven sequence: '{sequence4}', predicted next word: '{next_word4}'\")\n",
        "\n",
        "sequence5 = \"unknown words\"\n",
        "next_word5 = predict_next_word_trigram(sequence5, Trigrams_counts, bigram_counts)\n",
        "print(f\"\\nGiven sequence: '{sequence5}', predicted next word: '{next_word5}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AGVnIqIAdhr",
        "outputId": "4f5992dd-b1e9-414d-b8f0-f4ddb796cf54"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Possible next words for 'ai is':\n",
            "Probability of 'used' = 1.0\n",
            "\n",
            "Given sequence: 'ai is', predicted next word: 'used'\n",
            "\n",
            "Possible next words for 'nlp uses':\n",
            "Probability of 'language' = 1.0\n",
            "\n",
            "Given sequence: 'nlp uses', predicted next word: 'language'\n",
            "\n",
            "Possible next words for 'technology improves':\n",
            "Probability of 'education' = 1.0\n",
            "\n",
            "Given sequence: 'technology improves', predicted next word: 'education'\n",
            "\n",
            "Possible next words for 'smart systems':\n",
            "Probability of 'help' = 1.0\n",
            "\n",
            "Given sequence: 'smart systems', predicted next word: 'help'\n",
            "\n",
            "Given sequence: 'unknown words', predicted next word: 'No trigram found starting with 'unknown words.''\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Tri-Gram Model"
      ],
      "metadata": {
        "id": "FFJTdiG4GSof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmvgskz2BNBx",
        "outputId": "e1a8ee72-22f5-4ec1-8a2d-e12d6d36836e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textNLP uses\n",
            "\n",
            "Possible next words for 'nlp uses':\n",
            "Probability of 'language' = 1.0\n",
            "Given sequence: 'NLP uses', predicted next word: 'language'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Bi-Gram Counts with Laplace Smoothening*"
      ],
      "metadata": {
        "id": "sZ6c7aDNGNE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_Laplace(word_sequence, bigram_counts, unigram_counts, V):\n",
        "\n",
        "    # Tokenize input\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # If last word not in vocabulary\n",
        "    if last_word not in unigram_counts:\n",
        "        return f\"'{last_word}' not found in vocabulary.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = 0\n",
        "\n",
        "    print(f\"\\nPossible next words for '{last_word}' (Laplace Smoothed):\")\n",
        "\n",
        "    # Define vocab using unigram_counts keys\n",
        "    vocab = unigram_counts.keys()\n",
        "\n",
        "    # Check probability for ALL words in vocabulary\n",
        "    for word in vocab:\n",
        "\n",
        "        bigram_count = bigram_counts.get((last_word, word), 0)\n",
        "        unigram_count = unigram_counts.get(last_word, 0)\n",
        "\n",
        "        # Laplace Smoothing Formula\n",
        "        # P(w2 | w1) = (Count(w1,w2) + 1) / (Count(w1) + V)\n",
        "        probability = (bigram_count + 1) / (unigram_count + V)\n",
        "\n",
        "        # Print only meaningful probabilities (optional: remove if you want all)\n",
        "        if bigram_count > 0:\n",
        "            print(f\"Probability of '{word}' = {probability}\")\n",
        "\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = word\n",
        "\n",
        "    return predicted_word\n",
        "sequence1 = \"artificial\"\n",
        "next_word1 = predict_next_word_bigram_Laplace(sequence1, bigram_counts, unigram_counts, V)\n",
        "print(f\"\\nGiven sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"language\"\n",
        "next_word2 = predict_next_word_bigram_Laplace(sequence2, bigram_counts, unigram_counts, V)\n",
        "print(f\"\\nGiven sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"online\"\n",
        "next_word3 = predict_next_word_bigram_Laplace(sequence3, bigram_counts, unigram_counts, V)\n",
        "print(f\"\\nGiven sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"smart\"\n",
        "next_word4 = predict_next_word_bigram_Laplace(sequence4, bigram_counts, unigram_counts, V)\n",
        "print(f\"\\nGiven sequence: '{sequence4}', predicted next word: '{next_word4}'\")\n",
        "\n",
        "sequence5 = \"unknownword\"\n",
        "next_word5 = predict_next_word_bigram_Laplace(sequence5, bigram_counts, unigram_counts, V)\n",
        "print(f\"\\nGiven sequence: '{sequence5}', predicted next word: '{next_word5}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1ve3GvJBW8f",
        "outputId": "cc0dc822-c56b-4f0f-9ce3-1bbb0bf28c2e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Given sequence: 'artificial', predicted next word: ''artificial' not found in vocabulary.'\n",
            "\n",
            "Possible next words for 'language' (Laplace Smoothed):\n",
            "Probability of 'models' = 0.08695652173913043\n",
            "\n",
            "Given sequence: 'language', predicted next word: 'models'\n",
            "\n",
            "Given sequence: 'online', predicted next word: ''online' not found in vocabulary.'\n",
            "\n",
            "Possible next words for 'smart' (Laplace Smoothed):\n",
            "Probability of 'systems' = 0.08695652173913043\n",
            "\n",
            "Given sequence: 'smart', predicted next word: 'systems'\n",
            "\n",
            "Given sequence: 'unknownword', predicted next word: ''unknownword' not found in vocabulary.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Laplace Smoothening based Bi-Gram Model"
      ],
      "metadata": {
        "id": "vNOhbUifGGKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_Laplace(ip_text, bigram_counts, unigram_counts, V)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe80JHChCCSh",
        "outputId": "d9b0cfb2-377c-4478-e914-c61953a520a0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textNLP uses\n",
            "\n",
            "Possible next words for 'uses' (Laplace Smoothed):\n",
            "Probability of 'language' = 0.08695652173913043\n",
            "Given sequence: 'NLP uses', predicted next word: 'language'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Tri-Gram Counts based on laplace smoothening"
      ],
      "metadata": {
        "id": "b5jzlmHfF_Z6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_Laplace(word_sequence, Trigrams_counts, bigram_counts, V):\n",
        "\n",
        "    # Tokenize input\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words.\"\n",
        "\n",
        "    # Last two words\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Check if bigram exists\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{ ' '.join(last_two_words_tuple) }' not found as bigram.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = 0\n",
        "\n",
        "    print(f\"\\nPossible next words for '{' '.join(last_two_words_tuple)}' (Laplace Smoothed):\")\n",
        "\n",
        "    # Define vocab using unigram_counts keys\n",
        "    vocab = unigram_counts.keys()\n",
        "\n",
        "    # Check probability for ALL words in vocabulary\n",
        "    for word in vocab:\n",
        "\n",
        "        trigram_count = Trigrams_counts.get(\n",
        "            (last_two_words_tuple[0], last_two_words_tuple[1], word), 0\n",
        "        )\n",
        "\n",
        "        # Laplace Formula\n",
        "        # P(w3 | w1,w2) = (Count(w1,w2,w3) + 1) / (Count(w1,w2) + V)\n",
        "        probability = (trigram_count + 1) / (last_two_words_bigram_count + V)\n",
        "\n",
        "        # Print only seen trigrams (optional)\n",
        "        if trigram_count > 0:\n",
        "            print(f\"Probability of '{word}' = {probability}\")\n",
        "\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = word\n",
        "\n",
        "    return predicted_word\n",
        "sequence1 = \"artificial intelligence\"\n",
        "next_word1 = predict_next_word_trigram_Laplace(sequence1, Trigrams_counts, bigram_counts, V)\n",
        "print(f\"\\nGiven sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"natural language\"\n",
        "next_word2 = predict_next_word_trigram_Laplace(sequence2, Trigrams_counts, bigram_counts, V)\n",
        "print(f\"\\nGiven sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"online learning\"\n",
        "next_word3 = predict_next_word_trigram_Laplace(sequence3, Trigrams_counts, bigram_counts, V)\n",
        "print(f\"\\nGiven sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"smart systems\"\n",
        "next_word4 = predict_next_word_trigram_Laplace(sequence4, Trigrams_counts, bigram_counts, V)\n",
        "print(f\"\\nGiven sequence: '{sequence4}', predicted next word: '{next_word4}'\")\n",
        "\n",
        "sequence5 = \"unknown words\"\n",
        "next_word5 = predict_next_word_trigram_Laplace(sequence5, Trigrams_counts, bigram_counts, V)\n",
        "print(f\"\\nGiven sequence: '{sequence5}', predicted next word: '{next_word5}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh9EhTYwDbmp",
        "outputId": "1cdd1a52-656d-4d2a-efbb-afb54104a13a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Given sequence: 'artificial intelligence', predicted next word: ''artificial intelligence' not found as bigram.'\n",
            "\n",
            "Given sequence: 'natural language', predicted next word: ''natural language' not found as bigram.'\n",
            "\n",
            "Given sequence: 'online learning', predicted next word: ''online learning' not found as bigram.'\n",
            "\n",
            "Possible next words for 'smart systems' (Laplace Smoothed):\n",
            "Probability of 'help' = 0.08695652173913043\n",
            "\n",
            "Given sequence: 'smart systems', predicted next word: 'help'\n",
            "\n",
            "Given sequence: 'unknown words', predicted next word: ''unknown words' not found as bigram.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Laplace Smoothening based Tri-Gram Model**"
      ],
      "metadata": {
        "id": "c9LLyhiqFwIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_Laplace(ip_text, Trigrams_counts, bigram_counts, V)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US4tCvumDk0K",
        "outputId": "8ab4ef7b-49ce-4eb4-e2c8-62d1a078a83f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textAI is used\n",
            "\n",
            "Possible next words for 'is used' (Laplace Smoothed):\n",
            "Probability of 'in' = 0.08695652173913043\n",
            "Given sequence: 'AI is used', predicted next word: 'in'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Bi-Gram Counts with Add - K Smoothening"
      ],
      "metadata": {
        "id": "0KXdToc9FqDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_K(word_sequence, bigram_counts, unigram_counts, V, K):\n",
        "    # Tokenize input\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    if last_word not in unigram_counts:\n",
        "        return f\"'{last_word}' not found in vocabulary.\"\n",
        "\n",
        "    last_word_unigram_count = unigram_counts[last_word]\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = 0\n",
        "\n",
        "    print(f\"\\nPossible next words for '{last_word}' (Add-{K} Smoothing):\")\n",
        "\n",
        "    # Define vocab using unigram_counts keys\n",
        "    vocab = unigram_counts.keys()\n",
        "\n",
        "    # Check probability for ALL words in vocabulary\n",
        "    for word in vocab:\n",
        "\n",
        "        bigram_count = bigram_counts.get((last_word, word), 0)\n",
        "\n",
        "        # Add-K Smoothing Formula\n",
        "        # P(w2 | w1) = (Count(w1,w2) + K) / (Count(w1) + K*V)\n",
        "        probability = (bigram_count + K) / (last_word_unigram_count + K * V)\n",
        "\n",
        "        # Print only seen bigrams (optional)\n",
        "        if bigram_count > 0:\n",
        "            print(f\"Probability of '{word}' = {probability}\")\n",
        "\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = word\n",
        "\n",
        "    return predicted_word\n",
        "sequence1 = \"artificial\"\n",
        "next_word1 = predict_next_word_bigram_K(sequence1, bigram_counts, unigram_counts, V, 0.5)\n",
        "print(f\"\\nGiven sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"language\"\n",
        "next_word2 = predict_next_word_bigram_K(sequence2, bigram_counts, unigram_counts, V, 0.5)\n",
        "print(f\"\\nGiven sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"online\"\n",
        "next_word3 = predict_next_word_bigram_K(sequence3, bigram_counts, unigram_counts, V, 0.5)\n",
        "print(f\"\\nGiven sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"smart\"\n",
        "next_word4 = predict_next_word_bigram_K(sequence4, bigram_counts, unigram_counts, V, 0.5)\n",
        "print(f\"\\nGiven sequence: '{sequence4}', predicted next word: '{next_word4}'\")\n",
        "\n",
        "sequence5 = \"unknownword\"\n",
        "next_word5 = predict_next_word_bigram_K(sequence5, bigram_counts, unigram_counts, V, 0.5)\n",
        "print(f\"\\nGiven sequence: '{sequence5}', predicted next word: '{next_word5}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDsgD6v3D1Aa",
        "outputId": "03e120ba-eeb5-4b53-fa63-1fe928632c89"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Given sequence: 'artificial', predicted next word: ''artificial' not found in vocabulary.'\n",
            "\n",
            "Possible next words for 'language' (Add-0.5 Smoothing):\n",
            "Probability of 'models' = 0.125\n",
            "\n",
            "Given sequence: 'language', predicted next word: 'models'\n",
            "\n",
            "Given sequence: 'online', predicted next word: ''online' not found in vocabulary.'\n",
            "\n",
            "Possible next words for 'smart' (Add-0.5 Smoothing):\n",
            "Probability of 'systems' = 0.125\n",
            "\n",
            "Given sequence: 'smart', predicted next word: 'systems'\n",
            "\n",
            "Given sequence: 'unknownword', predicted next word: ''unknownword' not found in vocabulary.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Add-K Smoothening based Bi-Gram Model\n"
      ],
      "metadata": {
        "id": "rIiUUO0VFZEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_K(ip_text, bigram_counts, unigram_counts, V, 0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6H0mulxEMzR",
        "outputId": "bb8acb19-a076-471b-e3f3-8fb71f48160e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textAI is\n",
            "\n",
            "Possible next words for 'is' (Add-0.5 Smoothing):\n",
            "Probability of 'used' = 0.125\n",
            "Given sequence: 'AI is', predicted next word: 'used'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Tri-Gram Counts with Add - K Smoothening"
      ],
      "metadata": {
        "id": "cIfpd_FdFR9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_K(word_sequence, Trigrams_counts, bigram_counts, K):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Enter at least two words.\"\n",
        "\n",
        "    # Get last two words\n",
        "    last_two_words = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Vocabulary size\n",
        "    V = len(set([w3 for (_, _, w3) in Trigrams_counts.keys()]))\n",
        "\n",
        "    # Get bigram count (denominator)\n",
        "    bigram_count = bigram_counts.get(last_two_words, 0)\n",
        "\n",
        "    if bigram_count == 0:\n",
        "        return f\"No bigram found for '{' '.join(last_two_words)}'\"\n",
        "\n",
        "    max_probability = -1\n",
        "    predicted_word = None\n",
        "\n",
        "    # Check all possible trigrams\n",
        "    for (w1, w2, w3), trigram_count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words:\n",
        "            probability = (trigram_count + K) / (bigram_count + K * V)\n",
        "            print(f\"Probability of '{w3}' = {probability}\")\n",
        "\n",
        "            if probability > max_probability:\n",
        "                max_probability = probability\n",
        "                predicted_word = w3\n",
        "\n",
        "    if predicted_word is None:\n",
        "        return \"No trigram match found.\"\n",
        "\n",
        "    return predicted_word\n",
        "sequence1 = \"AI is used\"\n",
        "print(\"Next word:\", predict_next_word_trigram_K(sequence1, Trigrams_counts, bigram_counts, 0.5))\n",
        "\n",
        "sequence2 = \"NLP uses language\"\n",
        "print(\"Next word:\", predict_next_word_trigram_K(sequence2, Trigrams_counts, bigram_counts, 0.5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmloOArsEtl6",
        "outputId": "205ede6c-7b50-4df7-b84f-b8095d29e55e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of 'in' = 0.13636363636363635\n",
            "Next word: in\n",
            "Probability of 'models' = 0.13636363636363635\n",
            "Next word: models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Add-K Smoothening based Tri-Gram Model"
      ],
      "metadata": {
        "id": "OkKn-ZycFI-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_K(ip_text, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5ktqlZwE85t",
        "outputId": "52850ccc-ef9b-48ae-ecd3-ac7a53a0ecfd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textAI is used\n",
            "Probability of 'in' = 0.13636363636363635\n",
            "Given sequence: 'AI is used', predicted next word: 'in'\n"
          ]
        }
      ]
    }
  ]
}